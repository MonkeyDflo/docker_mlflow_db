# Have the following environment vars set in shell running docker-compose:
# DB_NAME
# DB_USER      # postgres admin user
# DB_PW        # postgres admin user's pw
# DB_PORT
# MLFLOW_PORT

version: '3.3'

services:
    db:
        restart: always
        image: postgres:latest
        container_name: mlflow_db
        expose:
            - ${DB_PORT}
        ports:
            - "${DB_PORT}:${DB_PORT}"
        environment:
            - POSTGRES_DB=${DB_NAME}
            - POSTGRES_USER=${DB_USER}
            - POSTGRES_PASSWORD=${DB_PW}
        volumes:
            - db_datapg:/var/lib/postgresql/data
        # Future TODO:
        # Let's put this postgres image in a new container defined in a subdir
        # after all, and add some lines in its Dockerfile that run PG cmdline
        # routines to add/config an mlflow user so we're not using postgres
        # admin/owner account for mlflow.  Then we'd have DBADMIN_USER and
        # DBADMIN_PW as well as MLFLOW_USER and MLFLOW_PW.

    app:
        restart: always
        build: ./mlflow
        image: mlflow_server
        container_name: mlflow_server
        expose:
            - ${MLFLOW_PORT}
        ports:
            - "${MLFLOW_PORT}:${MLFLOW_PORT}"
        environment:
            - BACKEND="postgresql://${DB_USER}:${DB_PW}@db:${DB_PORT}/${DB_NAME}"
            - ARTIFACTS="/mlruns"
          # Or for artifact store in AWS S3 bucket (note boto was installed in container):
          #  - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
          #  - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
          #  - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
          #  - ARTIFACTS="s3://mlflow_bucket/mlflow/"
        volumes:
            - mlrun_data:/mlruns
        command: mlflow server --port ${MLFLOW_PORT} --host 0.0.0.0 --backend-store-uri $${BACKEND} --default-artifact-root $${ARTIFACTS}
        depends_on:
            - db

volumes:
    db_datapg:
    mlrun_data:
